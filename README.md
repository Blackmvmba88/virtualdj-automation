# VirtualDJ MIDI Automation System

Sistema completo para automatizar VirtualDJ mediante control MIDI con observaciÃ³n de audio en tiempo real y aprendizaje adaptativo.

## ğŸ“‹ DescripciÃ³n

Este sistema implementa una soluciÃ³n completa para controlar VirtualDJ de forma automÃ¡tica mediante tres componentes principales:

1. **Controlador MIDI** (`midi_controller.py`): EnvÃ­a comandos MIDI a VirtualDJ para controlar reproducciÃ³n, mezclas, efectos y mÃ¡s.
2. **Observador de Audio** (`audio_observer.py`): Captura y analiza audio en tiempo real, extrayendo caracterÃ­sticas como RMS, energÃ­a, BPM y detecciÃ³n de beats.
3. **Agente Adaptativo** (`adaptive_agent.py`): Aprende y optimiza las mezclas mediante heurÃ­sticas, aprendizaje supervisado y aprendizaje por refuerzo.

## ğŸš€ CaracterÃ­sticas

### Controlador MIDI
- **Comandos de reproducciÃ³n**: Play/Pause, Cue, Sync para ambos decks
- **Control de mezcla**: Crossfader con transiciones suaves
- **Control de volumen**: Ajuste independiente por deck
- **Ecualizador**: Control de bajos, medios y agudos (3 bandas)
- **Efectos**: ActivaciÃ³n de hasta 3 efectos con control de intensidad
- **Carga de tracks**: SelecciÃ³n de pistas desde playlist

### Observador de Audio
- **Captura en tiempo real**: Stream de audio con buffer circular
- **AnÃ¡lisis de caracterÃ­sticas**:
  - RMS (Root Mean Square) y nivel en dB
  - EnergÃ­a de la seÃ±al
  - DetecciÃ³n de beats
  - EstimaciÃ³n de BPM
  - Centroide espectral
  - Rolloff espectral
  - Zero-crossing rate
  - **Balance espectral por bandas** (bajos, medios, agudos)
- **EstimaciÃ³n de calidad**: Score de calidad de mezcla en tiempo real (0.0-1.0)
- **Lectura de estado**: IntegraciÃ³n con estado de VirtualDJ

### Agente Adaptativo
- **Modo HeurÃ­stico**: Reglas basadas en experiencia musical
  - Transiciones suaves en beats
  - Mantenimiento de niveles Ã³ptimos de RMS
  - Ajustes de EQ segÃºn contenido espectral
  - AplicaciÃ³n inteligente de efectos
- **Modo Aprendizaje Supervisado**: 
  - ClasificaciÃ³n de acciones mediante Random Forest
  - Escalado de caracterÃ­sticas
  - Entrenamiento con datos histÃ³ricos
- **Modo Aprendizaje por Refuerzo** (Q-Learning):
  - ExploraciÃ³n vs explotaciÃ³n (epsilon-greedy)
  - ActualizaciÃ³n de valores Q
  - Buffer de experiencia
  - Decaimiento de exploraciÃ³n
  - **Sistema de Recompensas Optimizado**:
    - RMS Level (sweet spot): Mantiene niveles Ã³ptimos de audio
    - BPM Matching: SincronizaciÃ³n entre decks
    - Energy Flow: Transiciones suaves de energÃ­a
    - Crossfader Behavior: Movimientos coherentes y beat-aligned
    - Spectral Balance: Balance de frecuencias (bajos, medios, agudos)
    - Penalizaciones por clipping y silencio
    - Pesos configurables para cada componente

## ğŸ“¦ InstalaciÃ³n

### Requisitos Previos
- Python 3.8 o superior
- loopMIDI (Windows) o virtual MIDI port (Linux/Mac)
- VirtualDJ configurado para recibir MIDI
- Interfaz de audio para captura

### InstalaciÃ³n de Dependencias

```bash
# Clonar el repositorio
git clone https://github.com/Blackmvmba88/virtualdj-automation.git
cd virtualdj-automation

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales
- `mido`: ComunicaciÃ³n MIDI
- `python-rtmidi`: Backend MIDI en tiempo real
- `numpy`: Procesamiento numÃ©rico
- `scipy`: Procesamiento de seÃ±ales
- `librosa`: AnÃ¡lisis de audio
- `sounddevice`: Captura de audio
- `scikit-learn`: Aprendizaje automÃ¡tico
- `tensorflow`: Deep learning (opcional para extensiones futuras)

## ğŸ® ConfiguraciÃ³n

### 1. Configurar loopMIDI (Windows)

1. Descargar e instalar [loopMIDI](https://www.tobias-erichsen.de/software/loopmidi.html)
2. Crear un puerto MIDI virtual (ej: "VirtualDJ Automation")
3. Iniciar el puerto

### 2. Configurar VirtualDJ

1. Abrir VirtualDJ
2. Ir a Settings â†’ MIDI
3. Agregar el puerto MIDI virtual creado
4. Mapear los controles segÃºn la configuraciÃ³n en `midi_controller.py`

### 3. Configurar Captura de Audio

```python
# Listar dispositivos de audio disponibles
import sounddevice as sd
print(sd.query_devices())

# Usar el Ã­ndice del dispositivo deseado en AudioObserver
observer = AudioObserver(device=INDEX)
```

## ğŸ¯ Uso

### Modo BÃ¡sico - Script de Prueba

```bash
python test_script.py
```

El script de prueba ofrece un menÃº interactivo con las siguientes opciones:

1. **Demo: Comandos MIDI BÃ¡sicos** - Prueba individual de cada comando
2. **Demo: AnÃ¡lisis de Audio** - Captura y anÃ¡lisis de caracterÃ­sticas
3. **Demo: Modos de Aprendizaje** - ComparaciÃ³n de diferentes estrategias
4. **Ejecutar Sistema Completo** - AutomatizaciÃ³n por 30 segundos
5. **Ejecutar con DuraciÃ³n Personalizada** - Control total del tiempo

### Uso ProgramÃ¡tico

#### Ejemplo 1: Control MIDI Simple

```python
from midi_controller import VirtualDJMIDIController
import time

# Inicializar controlador
controller = VirtualDJMIDIController()

# Reproducir deck A
controller.play_pause_deck('A')
time.sleep(2)

# TransiciÃ³n suave a deck B
controller.crossfade_transition('A', 'B', duration=4.0)

# Aplicar efecto
controller.activate_effect(1, intensity=0.7)

# Cerrar conexiÃ³n
controller.close()
```

#### Ejemplo 2: AnÃ¡lisis de Audio

```python
from audio_observer import AudioObserver
import time

# Inicializar observador
observer = AudioObserver(sample_rate=44100)

# Iniciar captura
observer.start_streaming()

# Capturar por 5 segundos
for i in range(5):
    time.sleep(1)
    features = observer.get_features()
    print(f"RMS: {features['rms_db']:.1f} dB, BPM: {features['bpm']:.1f}")

# AnÃ¡lisis de buffer
analysis = observer.analyze_buffer(duration=2.0)
print(f"Tempo estimado: {analysis['estimated_tempo']:.1f} BPM")

# Detener captura
observer.stop_streaming()
```

#### Ejemplo 3: Agente Adaptativo

```python
from adaptive_agent import AdaptiveAgent
from audio_observer import AudioObserver
from midi_controller import VirtualDJMIDIController

# Inicializar componentes
agent = AdaptiveAgent(learning_mode='reinforcement')
observer = AudioObserver()
controller = VirtualDJMIDIController()

# Iniciar observaciÃ³n
observer.start_streaming()

# Loop de automatizaciÃ³n
for iteration in range(100):
    # Obtener estado actual
    audio_features = observer.get_features()
    vdj_state = observer.get_vdj_state()
    
    # Agente decide acciÃ³n
    actions = agent.decide_action_reinforcement(audio_features, vdj_state)
    
    # Ejecutar acciones
    if actions['crossfade_adjust'] != 0.0:
        current_pos = vdj_state['crossfader_position']
        new_pos = current_pos + actions['crossfade_adjust']
        controller.set_crossfader(new_pos)
    
    # Calcular recompensa y aprender
    reward = agent.calculate_reward(audio_features, vdj_state)
    agent.update_q_value(reward)
    
    time.sleep(1.0)

# Guardar modelos aprendidos
agent.save()
```

#### Ejemplo 4: Sistema Completo

```python
from test_script import VirtualDJAutomationSystem

# Crear sistema con aprendizaje por refuerzo
system = VirtualDJAutomationSystem(
    midi_port="VirtualDJ Automation",
    learning_mode='reinforcement'
)

# Ejecutar por 60 segundos con actualizaciones cada 2 segundos
system.run_automation_loop(duration=60.0, update_interval=2.0)
```

## ğŸ§  Modos de Aprendizaje

### HeurÃ­stico (Reglas)
- Ideal para comenzar
- Comportamiento predecible
- Basado en mejores prÃ¡cticas de DJing
- Sin necesidad de entrenamiento

**CuÃ¡ndo usar**: Para resultados inmediatos y consistentes.

### Supervisado
- Requiere datos de entrenamiento etiquetados
- Aprende de ejemplos de mezclas exitosas
- Modelo Random Forest para clasificaciÃ³n
- Guardado/carga de modelos

**CuÃ¡ndo usar**: Cuando tienes grabaciones de mezclas de referencia.

### Refuerzo (Q-Learning)
- Aprende por ensayo y error
- Optimiza basado en recompensas
- Explora nuevas estrategias
- Mejora con el tiempo

**CuÃ¡ndo usar**: Para optimizaciÃ³n continua y adaptaciÃ³n a diferentes estilos.

#### Sistema de Recompensas

El modo de refuerzo utiliza un sistema de recompensas multi-componente que evalÃºa:

**FÃ³rmula de Recompensa Total:**
```
R_total = w_rms Ã— R_mix + w_bpm Ã— R_bpm + w_energy Ã— R_energy + 
          w_xfade Ã— R_xfade + w_spectral Ã— R_spectral - P_clipping - P_silence
```

**Componentes de Recompensa:**

1. **R_mix (RMS + Calidad)**: EvalÃºa nivel de audio en "sweet spot" (-16 dB Â± 8 dB)
   - Penaliza clipping (> -1 dB) y niveles muy bajos (< -40 dB)
   - Combina con score de calidad general

2. **R_bpm**: Recompensa por matching de BPM entre decks
   - MÃ¡ximo reward cuando BPMs coinciden
   - Penaliza diferencias > 6 BPM

3. **R_energy**: EvalÃºa fluidez de transiciones energÃ©ticas
   - Recompensa cambios suaves (< 0.4)
   - Penaliza saltos abruptos de energÃ­a

4. **R_xfade**: EvalÃºa comportamiento del crossfader
   - Recompensa movimientos coherentes (0.02 - 0.3)
   - Bonus por transiciones en beat
   - Penaliza micro-movimientos o cambios bruscos

5. **R_spectral**: Balance de frecuencias (bajos, medios, agudos)
   - Recompensa distribuciÃ³n equilibrada
   - Penaliza exceso de bajos o desbalances extremos

**Pesos por Defecto:**
- w_rms: 0.25
- w_bpm: 0.20
- w_energy: 0.15
- w_xfade: 0.20
- w_spectral: 0.20

**Penalizaciones:**
- Silencio (< -55 dB): -0.7
- Clipping (> -3 dB): -0.5

Los pesos son ajustables segÃºn el estilo de mezcla deseado.

## ğŸ“Š MÃ©tricas y AnÃ¡lisis

El sistema proporciona mÃ©tricas detalladas:

### Audio
- **RMS**: Nivel de amplitud (-80 a 0 dB)
- **EnergÃ­a**: Potencia de la seÃ±al
- **BPM**: Tempo detectado
- **Calidad**: Score 0.0-1.0 basado en mÃºltiples factores

### Aprendizaje
- **Recompensa promedio**: Rendimiento del agente
- **Tasa de exploraciÃ³n**: Balance exploraciÃ³n/explotaciÃ³n
- **TamaÃ±o Q-table**: Estados aprendidos
- **Tendencia de recompensa**: Mejora reciente

## ğŸ› ï¸ Mapeo MIDI

El controlador utiliza los siguientes mapeos MIDI por defecto:

| Control | Tipo | CC/Note | DescripciÃ³n |
|---------|------|---------|-------------|
| Play/Pause Deck A | Note | 0x01 | Toggle reproducciÃ³n |
| Play/Pause Deck B | Note | 0x02 | Toggle reproducciÃ³n |
| Cue Deck A | Note | 0x03 | Punto Cue |
| Cue Deck B | Note | 0x04 | Punto Cue |
| Sync Deck A | Note | 0x05 | Sincronizar BPM |
| Sync Deck B | Note | 0x06 | Sincronizar BPM |
| Crossfader | CC | 0x07 | PosiciÃ³n 0-127 |
| Volume Deck A | CC | 0x08 | Volumen 0-127 |
| Volume Deck B | CC | 0x09 | Volumen 0-127 |
| EQ Low A | CC | 0x0A | Bajos Deck A |
| EQ Mid A | CC | 0x0B | Medios Deck A |
| EQ High A | CC | 0x0C | Agudos Deck A |
| EQ Low B | CC | 0x0D | Bajos Deck B |
| EQ Mid B | CC | 0x0E | Medios Deck B |
| EQ High B | CC | 0x0F | Agudos Deck B |
| Effect 1 | CC | 0x10 | Efecto 1 |
| Effect 2 | CC | 0x11 | Efecto 2 |
| Effect 3 | CC | 0x12 | Efecto 3 |
| Load Track A | CC | 0x20 | Cargar pista Deck A |
| Load Track B | CC | 0x21 | Cargar pista Deck B |

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "No MIDI output ports available"
- Verificar que loopMIDI estÃ© ejecutÃ¡ndose
- Reiniciar el puerto MIDI virtual
- Verificar permisos de acceso

### Error: "Audio stream status"
- Verificar configuraciÃ³n de interfaz de audio
- Probar con otro dispositivo de entrada
- Ajustar buffer size y sample rate

### Las transiciones no son suaves
- Aumentar `steps` en `crossfade_transition()`
- Ajustar `optimal_crossfade_duration` en el agente
- Verificar sincronizaciÃ³n de BPM

### El agente no aprende correctamente
- Aumentar tiempo de entrenamiento
- Ajustar learning_rate y discount_factor
- Verificar que las recompensas sean apropiadas

## ğŸ“ Estructura del Proyecto

```
virtualdj-automation/
â”œâ”€â”€ midi_controller.py           # Control MIDI de VirtualDJ
â”œâ”€â”€ audio_observer.py             # Captura y anÃ¡lisis de audio
â”œâ”€â”€ adaptive_agent.py             # Agente de aprendizaje adaptativo
â”œâ”€â”€ test_script.py               # Script de prueba y demostraciÃ³n
â”œâ”€â”€ test_unit.py                 # Tests unitarios
â”‚
â”œâ”€â”€ ğŸŒˆ MÃ³dulos PsicodÃ©licos:
â”œâ”€â”€ dj_persona.py                # Sistema de personalidades DJ
â”œâ”€â”€ introspective_metrics.py     # MÃ©tricas psicolÃ³gicas del agente
â”œâ”€â”€ semantic_analyzer.py         # AnÃ¡lisis semÃ¡ntico musical
â”œâ”€â”€ psychedelic_visualizer.py    # Motor de visualizaciÃ³n OpenGL
â”œâ”€â”€ machine_spirit.py            # Generador de poesÃ­a
â”œâ”€â”€ psychedelic_demo.py          # Demo completo psicodÃ©lico
â”‚
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ .gitignore                  # Archivos ignorados por Git
â””â”€â”€ README.md                   # Esta documentaciÃ³n
```

## ğŸ“ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VirtualDJ Software                     â”‚
â”‚              (Reproduce audio, mezcla)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                           â”‚
             â”‚ MIDI Commands             â”‚ Audio Output
             â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MIDI Controller       â”‚    â”‚   Audio Observer        â”‚
â”‚  - Play/Pause           â”‚    â”‚  - Captura audio        â”‚
â”‚  - Crossfader           â”‚    â”‚  - Extrae features      â”‚
â”‚  - Effects              â”‚    â”‚  - Detecta beats        â”‚
â”‚  - EQ                   â”‚    â”‚  - Estima BPM           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                           â”‚
             â”‚ Actions                   â”‚ Features & State
             â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Adaptive Agent                             â”‚
â”‚  Modes:                                                 â”‚
â”‚  - Heuristic (Rule-based)                              â”‚
â”‚  - Supervised Learning (Random Forest)                 â”‚
â”‚  - Reinforcement Learning (Q-Learning)                 â”‚
â”‚                                                         â”‚
â”‚  Optimiza mezclas basÃ¡ndose en:                        â”‚
â”‚  - CaracterÃ­sticas de audio                            â”‚
â”‚  - Estado de VirtualDJ                                 â”‚
â”‚  - Experiencia aprendida                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸŒˆ CaracterÃ­sticas PsicodÃ©licas

### DJ Personas (dj_persona.py)

El sistema incluye **4 personalidades de DJ** que alteran el estilo de mezcla:

#### Personas Disponibles

1. **Techno Detroit** ğŸ­
   - Minimal, industrial, hipnÃ³tico
   - BPM: 125-135
   - Transiciones lentas y profundas
   - EQ minimalista
   - Factor experimental: 0.3

2. **Psy-Trance Goa** ğŸ•‰ï¸
   - PsicodÃ©lico, trippy, alta energÃ­a
   - BPM: 138-148
   - Uso intensivo de efectos
   - EQ dinÃ¡mico
   - Factor experimental: 0.6

3. **Latin Bass** ğŸ”¥
   - Reggaeton, dembow, perreo
   - BPM: 90-105
   - Cortes rÃ¡pidos
   - Ã‰nfasis en bajos
   - Factor experimental: 0.4

4. **Lo-Fi ChillHop** ğŸŒ™
   - Relajado, jazzy, nostÃ¡lgico
   - BPM: 70-95
   - Transiciones ultra-suaves
   - EQ cÃ¡lido
   - Factor experimental: 0.2

**Uso:**
```python
from dj_persona import PersonaAgent

# Crear agente con personalidad
agent = PersonaAgent(learning_mode='reinforcement', persona='psytrance_goa')

# Cambiar personalidad
agent.change_persona('techno_detroit')

# Listar personalidades disponibles
personas = PersonaAgent.list_personas()
```

### MÃ©tricas Introspectivas (introspective_metrics.py)

Sistema que expone el estado interno del agente como **mÃ©tricas psicolÃ³gicas**:

#### MÃ©tricas Disponibles

- **Ansiedad (Anxiety)** ğŸ˜°: Incertidumbre del agente (tasa de exploraciÃ³n)
- **Confianza (Confidence)** ğŸ’ª: Rendimiento percibido (recompensa promedio)
- **FantasÃ­a (Fantasy)** ğŸŒŸ: Voluntad de experimentar
- **Salud de Memoria** ğŸ§ : RetenciÃ³n de experiencias
- **Enfoque (Focus)** ğŸ¯: Consistencia en decisiones
- **ExcitaciÃ³n (Excitement)** âš¡: Respuesta a alta energÃ­a

**Estados Derivados:**
- Mood: euphoric, confident, anxious, experimental, focused, calm, balanced
- Creative State: highly_creative, creative, moderate, conservative
- Learning Phase: early_exploration, active_learning, exploitation, experimentation, refinement

**Uso:**
```python
from introspective_metrics import IntrospectiveMetrics

metrics = IntrospectiveMetrics()

# Actualizar mÃ©tricas
metrics.update(agent_state, audio_features, action)

# Obtener estado psicolÃ³gico
state = metrics.get_state()
print(f"Ansiedad: {state['anxiety']:.2f}")
print(f"Mood: {state['mood']}")

# DescripciÃ³n narrativa
description = metrics.get_narrative_description()
print(description)
```

### AnÃ¡lisis SemÃ¡ntico Musical (semantic_analyzer.py)

AnÃ¡lisis musical de alto nivel mÃ¡s allÃ¡ de caracterÃ­sticas bÃ¡sicas:

#### CaracterÃ­sticas Detectadas

- **Densidad Percusiva**: QuÃ© tan cargado de percusiÃ³n estÃ¡ el audio
- **Armonicidad vs Disonancia**: Contenido armÃ³nico vs atonal
- **Presencia Vocal**: DetecciÃ³n de voces
- **Escena ArmÃ³nica**: Modo (mayor/menor), tono emocional
- **Textura Musical**: sparse, dense, layered, percussive, harmonic, ambient

#### Escenas ArmÃ³nicas

- `major_bright`: Mayor con baja disonancia (uplifting)
- `major_energetic`: Mayor con disonancia moderada (energetic)
- `minor_dark`: Menor con alta disonancia (dark)
- `atonal_chaotic`: Baja armonÃ­a, alta disonancia (intense)
- `percussive_neutral`: Baja armonÃ­a, baja disonancia (rhythmic)

**Uso:**
```python
from semantic_analyzer import MusicalSemanticAnalyzer

analyzer = MusicalSemanticAnalyzer()

# Analizar buffer de audio
semantic_features = analyzer.analyze(audio_buffer, audio_features)

print(f"Densidad percusiva: {semantic_features['percussive_density']:.2f}")
print(f"Presencia vocal: {semantic_features['vocal_presence']:.2f}")
print(f"Escena: {semantic_features['harmonic_scene']}")
print(f"Tono emocional: {semantic_features['emotional_tone']}")

# RecomendaciÃ³n de transiciÃ³n
recommendation = analyzer.get_transition_recommendation(scene1, scene2)
print(f"Tipo: {recommendation['transition_type']}")
print(f"DuraciÃ³n: {recommendation['duration']}s")
```

### VisualizaciÃ³n PsicodÃ©lica (psychedelic_visualizer.py)

Motor de visualizaciÃ³n en tiempo real reactivo al audio y estado del agente:

#### CaracterÃ­sticas Visuales

- **Fractales de Fondo**: Patrones geomÃ©tricos animados
- **CÃ­rculos de EnergÃ­a**: Pulsos basados en energÃ­a
- **Pulso de Beat**: Flash visual en beats
- **DivisiÃ³n de Crossfader**: Split visual entre decks
- **DistorsiÃ³n por Reward**: Caos visual basado en rendimiento
- **Paletas de Color**: Colores basados en mood del agente

#### Modos de VisualizaciÃ³n

1. **OpenGL Mode**: VisualizaciÃ³n completa con shaders (requiere pygame + PyOpenGL)
2. **ASCII Mode**: VisualizaciÃ³n en terminal (fallback)

**Uso:**
```python
from psychedelic_visualizer import create_visualizer

# Crear visualizador (auto-detecta OpenGL o usa ASCII)
viz = create_visualizer(mode='auto', width=800, height=600)

# Iniciar
viz.start()

# Actualizar estado
viz.update(audio_features, agent_state, vdj_state)

# Detener
viz.stop()
```

**InstalaciÃ³n de dependencias de visualizaciÃ³n:**
```bash
pip install pygame PyOpenGL
```

### Machine Spirit - Generador de PoesÃ­a (machine_spirit.py)

El "EspÃ­ritu de la MÃ¡quina" genera poesÃ­a sobre las acciones del agente:

#### Tipos de PoesÃ­a

1. **Action Poems**: Descripciones poÃ©ticas de acciones individuales
2. **State Poems**: Reflexiones sobre el estado psicolÃ³gico
3. **Session Epilogue**: Ã‰pica final de la sesiÃ³n
4. **Random Wisdom**: Citas filosÃ³ficas sobre el DJing

**Ejemplos de Salida:**
```
The crossfader slides like a serpent of light
the beat strikes
energy explodes outward
and harmony reigns
```

```
Lost in the labyrinth of possibilities
Each path uncertain, each choice a mystery
The music roars like a storm
And the beat carries me home
```

**Uso:**
```python
from machine_spirit import MachineSpiritPoet

poet = MachineSpiritPoet()

# Poema de acciÃ³n
poem = poet.generate_action_poem(action, audio_features, agent_state)
print(poem)

# Poema de estado
state_poem = poet.generate_state_poem(agent_state, audio_features)
print(state_poem)

# EpÃ­logo de sesiÃ³n
epilogue = poet.generate_session_epilogue(stats)
print(epilogue)

# SabidurÃ­a aleatoria
wisdom = poet.get_random_wisdom()
print(wisdom)
```

### Demo PsicodÃ©lico Completo (psychedelic_demo.py)

Script de demostraciÃ³n que integra todas las caracterÃ­sticas:

```bash
python psychedelic_demo.py
```

#### Opciones de Demo

1. Quick Demo (30s) - Techno Detroit
2. Psy-Trance Session (60s)
3. Latin Bass Session (45s)
4. Lo-Fi ChillHop (60s)
5. ComparaciÃ³n de Personas
6. Modo Solo PoesÃ­a
7. Showcase de VisualizaciÃ³n

**Uso ProgramÃ¡tico:**
```python
from psychedelic_demo import PsychedelicDJSystem

# Crear sistema completo
system = PsychedelicDJSystem(
    persona='psytrance_goa',
    enable_visualization=True,
    enable_poetry=True
)

# Ejecutar loop psicodÃ©lico
system.run_psychedelic_loop(duration=60.0, update_interval=3.0)
```

## ğŸ§  EPIC SYSTEM - Framework Educativo de DiseÃ±o de Circuitos

Este repositorio tambiÃ©n contiene documentaciÃ³n del **EPIC SYSTEM**, un framework educativo multi-capa para enseÃ±anza de diseÃ±o de circuitos electrÃ³nicos:

### ğŸ“š DocumentaciÃ³n EPIC SYSTEM

- **[EPIC_SYSTEM.md](EPIC_SYSTEM.md)** - Framework completo de 7 capas (FÃ­sica, GeomÃ©trica, ElÃ©ctrica, SemÃ¡ntica, Cognitiva, PedagÃ³gica, EstÃ©tica)
- **[FIRST_CIRCUIT.md](FIRST_CIRCUIT.md)** - Circuito ejemplo: LED + Resistor limitadora, con anÃ¡lisis completo por capas
- **[RULE_ENGINE_0.1.md](RULE_ENGINE_0.1.md)** - EspecificaciÃ³n del motor de inferencia causal para diagnÃ³stico y enseÃ±anza

### ğŸ¯ PropÃ³sito

El EPIC SYSTEM transforma la electrÃ³nica de "conocimiento tribal" a cogniciÃ³n explÃ­cita, permitiendo:
- Razonamiento causal automÃ¡tico ("Si VCC < Vf entonces LED no ilumina")
- DiagnÃ³stico inteligente de circuitos
- Tutoriales adaptativos
- ValidaciÃ³n de diseÃ±os
- GeneraciÃ³n de explicaciones pedagÃ³gicas

*"Convierte electrÃ³nica en lenguaje, y lenguaje en inferencia."*

## ğŸš§ Desarrollo Futuro

### Mejoras Planeadas
- [x] VisualizaciÃ³n en tiempo real âœ…
- [x] Sistema de personalidades DJ âœ…
- [x] AnÃ¡lisis semÃ¡ntico musical âœ…
- [x] MÃ©tricas psicolÃ³gicas del agente âœ…
- [ ] IntegraciÃ³n directa con VirtualDJ API
- [ ] Soporte para mÃ¡s controladores MIDI fÃ­sicos
- [ ] Deep Q-Network (DQN) para aprendizaje profundo
- [ ] Control por visiÃ³n/gestos (Kinect/webcam)
- [ ] AnÃ¡lisis de reacciÃ³n del pÃºblico
- [ ] AnÃ¡lisis de gÃ©nero musical
- [ ] RecomendaciÃ³n de prÃ³xima pista
- [ ] GrabaciÃ³n y replay de sesiones
- [ ] Soporte multi-idioma
- [ ] Plugin para VirtualDJ

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo LICENSE para mÃ¡s detalles.

## ğŸ‘¥ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“§ Contacto

Para preguntas, sugerencias o reportar problemas, por favor abre un issue en GitHub.

## ğŸ™ Agradecimientos

- VirtualDJ por su excelente software de DJ
- Tobias Erichsen por loopMIDI
- Comunidad de Python audio/ML por las bibliotecas utilizadas

---

**Nota**: Este es un proyecto educativo y de investigaciÃ³n. Para uso en presentaciones en vivo, se recomienda supervisiÃ³n humana y pruebas exhaustivas.
